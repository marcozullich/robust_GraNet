data:
  dataset: "mnist"
  hyperparameters:
    dataset_root: "${DATASET_PATH}/mnist"
    batch_train: 128
    batch_test: 512
    transform_train: "bare_minimum"
    transform_test: "bare_minimum"
    manual_seed_valid_split: 123
    manual_seed_trainloader: 456
net: "FCN4"
train:
  epochs: 5
  burnout_epochs: 0
  clip_grad_norm: True
  checkpoint_path: checkpoints/mnist.pt
  checkpoint_save_time: epoch
  resume_training: False
  final_model_save_path: models/mnist.pt
  optim:
    _class: "SGD"
    hyperparameters:
      lr: 0.1
      weight_decay: !!float 5e-4
      momentum: 0.9
    scheduler:
      _class: "MultiStepLR"
      update_time: "epoch"
      hyperparameters:
        gamma: 0.1
        milestones: [7, 11]
  loss: "Cross Entropy"      
  pruning:
    mask_class: "NoMask"
    hyperparameters:
      init_pruning_rate: 0.0
      pruning_frequency: 200
      params_to_prune: [.1., .4., .7., .10.]
      initial_sparsity: 0.0
      final_sparsity: 0.9
    
        

