data:
  dataset: "cifar10"
  hyperparameters:
    root: "${DATASET_PATH}/cifar"
    batch_size_train: 128
    batch_size_test: 512
    pin_memory: True
    num_workers: 4
    manual_seed_trainloader: !!null
net: "PreActResNet18"
global_seed: !!null
train:
  epochs: 50
  burnout_epochs: 5
  clip_grad_norm_before_epoch: 5
  checkpoint_path: checkpoints/cifar10.pt #!!null
  checkpoint_save_time: "epoch"
  resume_training: False
  final_model_save_path: models/cifar10_unpruned_lin.pt
  dtype: half
  amp_hyperparameters:
    opt_level: "O0"
    loss_scale: 1.0
    master_weights: True
  optim:
    class: "SGD"
    hyperparameters:
      weight_decay: !!float 5e-4
      momentum: 0.9
      nesterov: True
      lr: 0.1
    scheduler:
      class: "MultiStepLR"
      update_time: "epoch"
      hyperparameters:
        gamma: 0.1
        milestones: [25, 40, 50]
  loss: "Cross Entropy"
  pruning:
    mask_class: "NoMask"
    #mask_class: "RGraNetMask"
    hyperparameters:
      init_pruning_rate: 0.0
      pruning_frequency: 500
      params_to_prune: ["prep.0", "conv", "shortcut", "classifier"]
      death_and_regrowth_rate: 0.5
      accumulate_gradients_before_regrowth: True
    
        
util:
  telegram_config_path: "telegram_config/config.yaml"
  telegram_config_name: !!null #"cifar10" # leave !!null for no telegram

deterministic: False

distributed:
  slurm: True
  ngpus: 4
  nnodes: 2
  nodelist: !!null
  partition: m100_usr_prod
  qos: m100_qos_dbg
  account: uTS22_Zullich2
  mail_type: "ALL"
  mail_user: "marco.zullich@gmail.com"
  logs_folder: slurm_logs
  max_num_timeout: 30
  port: !!null

